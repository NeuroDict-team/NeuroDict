{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba576f4-81fe-4e58-ade8-484f531e1003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import whisper\n",
    "import mlflow\n",
    "from IPython.display import Audio, display\n",
    "import shutil\n",
    "\n",
    "# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
    "audio_dir = Path(\"data/raw\")\n",
    "output_text_dir = Path(\"data/text\")\n",
    "output_text_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_audio_dir = Path(\"data/processed\")\n",
    "output_audio_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# –ò–º—è —Ñ–∞–π–ª–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º (–¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)\n",
    "reference_text_file = output_text_dir / \"reference.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c4cf816-805c-48de-b72f-7f4c22cdb6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ú–æ–¥–µ–ª—å Whisper –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "print(\"‚úÖ –ú–æ–¥–µ–ª—å Whisper –∑–∞–≥—Ä—É–∂–µ–Ω–∞\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa07bcaf-5b28-41c4-b1d5-623c86ab0215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from pathlib import Path\n",
    "\n",
    "audio_dir = Path(\"data/raw\")\n",
    "predicted_dir = Path(\"data/text/predicted\")\n",
    "predicted_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "for audio_file in audio_dir.glob(\"*.wav\"):\n",
    "    print(\"üéß –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º:\", audio_file.name, flush=True)\n",
    "    \n",
    "    result = model.transcribe(str(audio_file))\n",
    "    predicted_text = result[\"text\"]\n",
    "    \n",
    "    predicted_file = predicted_dir / (audio_file.stem + \"_predicted.txt\")\n",
    "    predicted_file.write_text(predicted_text, encoding=\"utf-8\")\n",
    "    \n",
    "    print(\"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω:\", predicted_file, flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd19dd-8852-49fe-8546-e2eb0c87ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_voice(text, voice_source, output_file):\n",
    "    \"\"\"\n",
    "    –ü–æ–∫–∞ –∑–∞–≥–ª—É—à–∫–∞: –∫–æ–ø–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ.\n",
    "    –í –±—É–¥—É—â–µ–º —Å—é–¥–∞ –º–æ–∂–Ω–æ –ø–æ–¥—Å—Ç–∞–≤–∏—Ç—å —Ä–µ–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å TTS.\n",
    "    \"\"\"\n",
    "    shutil.copy(voice_source, output_file)\n",
    "    print(f\"üéµ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –∞—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_file}\")\n",
    "\n",
    "for audio_file in audio_dir.glob(\"*.wav\"):\n",
    "    output_audio_file = output_audio_dir / (audio_file.stem + \"_fixed.wav\")\n",
    "    predicted_file = output_text_dir / (audio_file.stem + \"_transcript.txt\")\n",
    "    predicted_text = predicted_file.read_text(encoding=\"utf-8\")\n",
    "    \n",
    "    synthesize_voice(predicted_text, audio_file, output_audio_file)\n",
    "    \n",
    "    # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä—è–º–æ –≤ –Ω–æ—É—Ç–±—É–∫–µ\n",
    "    display(Audio(str(output_audio_file)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
